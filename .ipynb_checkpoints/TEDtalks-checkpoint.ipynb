{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TED Talk Transcripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working Script for Soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import glob, re, csv\n",
    "from bs4 import BeautifulSoup as soup                                                     \n",
    "\n",
    "the_file = \"/Users/john/Code/tedtalks/test/transcript?language=en.0\"\n",
    "holding = soup(open(the_file).read(), \"lxml\")\n",
    "at = holding.find(\"title\").text\n",
    "author = at[0:at.find(':')]\n",
    "title  = at[at.find(\":\")+1 : at.find(\"|\") ]\n",
    "date = re.sub('[^a-zA-Z0-9]',' ', holding.select_one(\"span.meta__val\").text)\n",
    "length_data = holding.find_all('data', {'class' : 'talk-transcript__para__time'})\n",
    "(m, s) = ([x.get_text().strip(\"\\n\\r\") \n",
    "      for x in length_data if re.search(r\"(?s)\\d{2}:\\d{2}\", \n",
    "                                        x.get_text().strip(\"\\n\\r\"))][-1]).split(':')\n",
    "length = int(m) * 60 + int(s)\n",
    "firstpass = re.sub(r'\\([^)]*\\)', '', holding.find('div', class_ = 'talk-transcript__body').text)\n",
    "text = re.sub('[^a-zA-Z\\.\\']',' ', firstpass)\n",
    "data = [str(author), str(title)]\n",
    "# print(data)\n",
    "with open(\"./output.csv\", \"w\", newline = \"\") as csv_file:\n",
    "        writer = csv.writer(csv_file, delimiter=',')\n",
    "        for item in data:\n",
    "            writer.writerow(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working Bit to Read a Directory into a List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/john/Code/tedtalks/test/transcript?language=en.0', '/Users/john/Code/tedtalks/test/transcript?language=en.1', '/Users/john/Code/tedtalks/test/transcript?language=en.2']\n"
     ]
    }
   ],
   "source": [
    "file_list = glob.glob('/Users/john/Code/tedtalks/test/*') # produces list\n",
    "print(file_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This Should Work... (but it doesn't)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Script to read 2113 texts and write them to a single csv \n",
    "# file with metadata for AUTHOR, TITLE, DATE, LENGTH.\n",
    "\n",
    "import glob, re, csv\n",
    "from bs4 import BeautifulSoup as soup                                                     \n",
    "\n",
    "file_list = glob.glob('/Users/john/Code/tedtalks/test/*') # produces list\n",
    "\n",
    "# Now to walk through list\n",
    "for the_file in file_list:\n",
    "    the_list = []\n",
    "    holding = soup(open(the_file).read(), \"lxml\")\n",
    "    at = holding.find(\"title\").text\n",
    "    author = at[0:at.find(':')]\n",
    "    title  = at[at.find(\":\")+1 : at.find(\"|\") ]\n",
    "    date = re.sub('[^a-zA-Z0-9]',' ', holding.select_one(\"span.meta__val\").text)\n",
    "    length_data = holding.find_all('data', {'class' : 'talk-transcript__para__time'})\n",
    "    (m, s) = ([x.get_text().strip(\"\\n\\r\") \n",
    "          for x in length_data if re.search(r\"(?s)\\d{2}:\\d{2}\", \n",
    "                                            x.get_text().strip(\"\\n\\r\"))][-1]).split(':')\n",
    "    length = int(m) * 60 + int(s)\n",
    "    firstpass = re.sub(r'\\([^)]*\\)', '', holding.find('div', class_ = 'talk-transcript__body').text)\n",
    "    text = re.sub('[^a-zA-Z\\.\\']',' ', firstpass)\n",
    "    the_list = the_list.append(author)\n",
    "    print(the_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working Script\n",
    "\n",
    "This is available in the repo as `text_to_csv.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import csv\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def parse(the_soup):\n",
    "    with open(the_soup, \"r\",encoding='utf-8', errors='ignore') as fdata:\n",
    "        # both title and author are can be parsed in separate tags.\n",
    "        author = the_soup.select_one(\"h4.h12.talk-link__speaker\").text\n",
    "        title = the_soup.select_one(\"h4.h9.m5\").text\n",
    "        # just need to strip the text from the date string, no regex needed.\n",
    "        date = the_soup.select_one(\"span.meta__val\").text.strip()      \n",
    "        # we want the last time which is the talk-transcript__para__time previous to the footer.\n",
    "        mn, sec = map(int, the_soup.select_one(\"footer.footer\").find_previous(\"data\", {\n",
    "        \"class\": \"talk-transcript__para__time\"}).text.split(\":\"))\n",
    "        length = (mn * 60 + sec)        \n",
    "        # to ignore (Applause) etc.. we can just pull from the actual text fragment checking for (\n",
    "        text = \" \".join(d.text for d in the_soup.select(\"span.talk-transcript__fragment\") if not d.text.startswith(\"(\"))        \n",
    "        # clean the text\n",
    "        text = re.sub('[^a-zA-Z\\.\\']', ' ', text)\n",
    "        return  author.strip(), title.strip(), date, length, text\n",
    "\n",
    "\n",
    "def to_csv(pth, out):\n",
    "    # open file to write to.\n",
    "    with open(out, \"w\") as out:\n",
    "        # create csv.writer. \n",
    "        wr = csv.writer(out)\n",
    "        # write our headers.\n",
    "        wr.writerow([\"author\", \"title\", \"date\", \"length\", \"text\"])\n",
    "        # get all our html files.\n",
    "        for html in os.listdir(pth):\n",
    "            with open(os.path.join(pth, html)) as f:\n",
    "                # parse the file are write the data to a row.\n",
    "                wr.writerow(parse(BeautifulSoup(f, \"lxml\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'codecs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-90-34c1d39489c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./test\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"test.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-89-59e7dc9b1562>\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(pth, out)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m# get all our html files.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhtml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhtml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m                 \u001b[0;31m# parse the file and write the data to a row.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                 \u001b[0mwr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriterow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"lxml\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'codecs' is not defined"
     ]
    }
   ],
   "source": [
    "to_csv(\"./test\",\"test.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
